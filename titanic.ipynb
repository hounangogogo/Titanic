{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic : Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Traing data ------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read data from files\n",
    "data = pd.read_csv('data_set/train.csv')\n",
    "print('------ Traing data ------')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "####  i. Fill in Null Data\n",
    "####  ii. Change 'Sex' part to int （male = 1， female = 0）\n",
    "####  iii. Keep the integer part, ignore char part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Before Preprocessing ------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
      "\n",
      "      Ticket     Fare Cabin Embarked  Deceased  \n",
      "0  A/5 21171   7.2500     0        S         1  \n",
      "1   PC 17599  71.2833   C85        C         0  \n",
      "\n",
      "\n",
      "------------ Start Preprocessing ------------\n",
      "     Sex   Age  Pclass  SibSp  Parch      Fare\n",
      "0      0  22.0       3      1      0    7.2500\n",
      "1      0  38.0       1      1      0   71.2833\n",
      "2      0  26.0       3      0      0    7.9250\n",
      "3      0  35.0       1      1      0   53.1000\n",
      "4      0  35.0       3      0      0    8.0500\n",
      "5      0   0.0       3      0      0    8.4583\n",
      "6      0  54.0       1      0      0   51.8625\n",
      "7      0   2.0       3      3      1   21.0750\n",
      "8      0  27.0       3      0      2   11.1333\n",
      "9      0  14.0       2      1      0   30.0708\n",
      "10     0   4.0       3      1      1   16.7000\n",
      "11     0  58.0       1      0      0   26.5500\n",
      "12     0  20.0       3      0      0    8.0500\n",
      "13     0  39.0       3      1      5   31.2750\n",
      "14     0  14.0       3      0      0    7.8542\n",
      "15     0  55.0       2      0      0   16.0000\n",
      "16     0   2.0       3      4      1   29.1250\n",
      "17     0   0.0       2      0      0   13.0000\n",
      "18     0  31.0       3      1      0   18.0000\n",
      "19     0   0.0       3      0      0    7.2250\n",
      "20     0  35.0       2      0      0   26.0000\n",
      "21     0  34.0       2      0      0   13.0000\n",
      "22     0  15.0       3      0      0    8.0292\n",
      "23     0  28.0       1      0      0   35.5000\n",
      "24     0   8.0       3      3      1   21.0750\n",
      "25     0  38.0       3      1      5   31.3875\n",
      "26     0   0.0       3      0      0    7.2250\n",
      "27     0  19.0       1      3      2  263.0000\n",
      "28     0   0.0       3      0      0    7.8792\n",
      "29     0   0.0       3      0      0    7.8958\n",
      "..   ...   ...     ...    ...    ...       ...\n",
      "861    0  21.0       2      1      0   11.5000\n",
      "862    0  48.0       1      0      0   25.9292\n",
      "863    0   0.0       3      8      2   69.5500\n",
      "864    0  24.0       2      0      0   13.0000\n",
      "865    0  42.0       2      0      0   13.0000\n",
      "866    0  27.0       2      1      0   13.8583\n",
      "867    0  31.0       1      0      0   50.4958\n",
      "868    0   0.0       3      0      0    9.5000\n",
      "869    0   4.0       3      1      1   11.1333\n",
      "870    0  26.0       3      0      0    7.8958\n",
      "871    0  47.0       1      1      1   52.5542\n",
      "872    0  33.0       1      0      0    5.0000\n",
      "873    0  47.0       3      0      0    9.0000\n",
      "874    0  28.0       2      1      0   24.0000\n",
      "875    0  15.0       3      0      0    7.2250\n",
      "876    0  20.0       3      0      0    9.8458\n",
      "877    0  19.0       3      0      0    7.8958\n",
      "878    0   0.0       3      0      0    7.8958\n",
      "879    0  56.0       1      0      1   83.1583\n",
      "880    0  25.0       2      0      1   26.0000\n",
      "881    0  33.0       3      0      0    7.8958\n",
      "882    0  22.0       3      0      0   10.5167\n",
      "883    0  28.0       2      0      0   10.5000\n",
      "884    0  25.0       3      0      0    7.0500\n",
      "885    0  39.0       3      0      5   29.1250\n",
      "886    0  27.0       2      0      0   13.0000\n",
      "887    0  19.0       1      0      0   30.0000\n",
      "888    0   0.0       3      1      2   23.4500\n",
      "889    0  26.0       1      0      0   30.0000\n",
      "890    0  32.0       3      0      0    7.7500\n",
      "\n",
      "[891 rows x 6 columns]\n",
      "     Deceased  Survived\n",
      "0           1         0\n",
      "1           0         1\n",
      "2           0         1\n",
      "3           0         1\n",
      "4           1         0\n",
      "5           1         0\n",
      "6           1         0\n",
      "7           1         0\n",
      "8           0         1\n",
      "9           0         1\n",
      "10          0         1\n",
      "11          0         1\n",
      "12          1         0\n",
      "13          1         0\n",
      "14          1         0\n",
      "15          0         1\n",
      "16          1         0\n",
      "17          0         1\n",
      "18          1         0\n",
      "19          0         1\n",
      "20          1         0\n",
      "21          0         1\n",
      "22          0         1\n",
      "23          0         1\n",
      "24          1         0\n",
      "25          0         1\n",
      "26          1         0\n",
      "27          1         0\n",
      "28          0         1\n",
      "29          1         0\n",
      "..        ...       ...\n",
      "861         1         0\n",
      "862         0         1\n",
      "863         1         0\n",
      "864         1         0\n",
      "865         0         1\n",
      "866         0         1\n",
      "867         1         0\n",
      "868         1         0\n",
      "869         0         1\n",
      "870         1         0\n",
      "871         0         1\n",
      "872         1         0\n",
      "873         1         0\n",
      "874         0         1\n",
      "875         0         1\n",
      "876         1         0\n",
      "877         1         0\n",
      "878         1         0\n",
      "879         0         1\n",
      "880         0         1\n",
      "881         1         0\n",
      "882         1         0\n",
      "883         1         0\n",
      "884         1         0\n",
      "885         1         0\n",
      "886         1         0\n",
      "887         0         1\n",
      "888         1         0\n",
      "889         0         1\n",
      "890         1         0\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('------------ Before Preprocessing ------------')\n",
    "# print the data before preprocessing\n",
    "dataset_X = data\n",
    "# Type is DataFrame\n",
    "print(type(dataset_X))\n",
    "\n",
    "# print the first 2 line of data\n",
    "print(dataset_X.iloc[0:2,:])\n",
    "\n",
    "print('\\n')\n",
    "print('------------ Start Preprocessing ------------')\n",
    "# fill in nan values with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# convert ['male', 'female'] values to [1, 0]\n",
    "data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "\n",
    "# add 'Deceased' as another class\n",
    "data['Deceased'] = data['Survived'].apply(lambda s: 1 - s)\n",
    "\n",
    "# select features and labels for training\n",
    "dataset_X = data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare']]\n",
    "dataset_Y = data[['Deceased', 'Survived']]\n",
    "\n",
    "print(dataset_X)\n",
    "print(dataset_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Divide dataset to (training set) and (test set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevent from overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaohaonan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "/Users/zhaohaonan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split training data and test data (30% is test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset_X.as_matrix(), \n",
    "    dataset_Y.as_matrix(), \n",
    "    test_size = 0.2, \n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
