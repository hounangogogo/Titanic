{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic : Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Traing data ------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read data from files\n",
    "data = pd.read_csv('data_set/train.csv')\n",
    "print('------ Traing data ------')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "####  i. Fill in Null Data\n",
    "####  ii. Change 'Sex' part to int （male = 1， female = 0）\n",
    "####  iii. Keep the integer part, ignore char part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Before Preprocessing ------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
      "\n",
      "      Ticket     Fare Cabin Embarked  Deceased  \n",
      "0  A/5 21171   7.2500     0        S         1  \n",
      "1   PC 17599  71.2833   C85        C         0  \n",
      "\n",
      "\n",
      "------------ Start Preprocessing ------------\n",
      "     Sex   Age  Pclass  SibSp  Parch      Fare\n",
      "0      0  22.0       3      1      0    7.2500\n",
      "1      0  38.0       1      1      0   71.2833\n",
      "2      0  26.0       3      0      0    7.9250\n",
      "3      0  35.0       1      1      0   53.1000\n",
      "4      0  35.0       3      0      0    8.0500\n",
      "5      0   0.0       3      0      0    8.4583\n",
      "6      0  54.0       1      0      0   51.8625\n",
      "7      0   2.0       3      3      1   21.0750\n",
      "8      0  27.0       3      0      2   11.1333\n",
      "9      0  14.0       2      1      0   30.0708\n",
      "10     0   4.0       3      1      1   16.7000\n",
      "11     0  58.0       1      0      0   26.5500\n",
      "12     0  20.0       3      0      0    8.0500\n",
      "13     0  39.0       3      1      5   31.2750\n",
      "14     0  14.0       3      0      0    7.8542\n",
      "15     0  55.0       2      0      0   16.0000\n",
      "16     0   2.0       3      4      1   29.1250\n",
      "17     0   0.0       2      0      0   13.0000\n",
      "18     0  31.0       3      1      0   18.0000\n",
      "19     0   0.0       3      0      0    7.2250\n",
      "20     0  35.0       2      0      0   26.0000\n",
      "21     0  34.0       2      0      0   13.0000\n",
      "22     0  15.0       3      0      0    8.0292\n",
      "23     0  28.0       1      0      0   35.5000\n",
      "24     0   8.0       3      3      1   21.0750\n",
      "25     0  38.0       3      1      5   31.3875\n",
      "26     0   0.0       3      0      0    7.2250\n",
      "27     0  19.0       1      3      2  263.0000\n",
      "28     0   0.0       3      0      0    7.8792\n",
      "29     0   0.0       3      0      0    7.8958\n",
      "..   ...   ...     ...    ...    ...       ...\n",
      "861    0  21.0       2      1      0   11.5000\n",
      "862    0  48.0       1      0      0   25.9292\n",
      "863    0   0.0       3      8      2   69.5500\n",
      "864    0  24.0       2      0      0   13.0000\n",
      "865    0  42.0       2      0      0   13.0000\n",
      "866    0  27.0       2      1      0   13.8583\n",
      "867    0  31.0       1      0      0   50.4958\n",
      "868    0   0.0       3      0      0    9.5000\n",
      "869    0   4.0       3      1      1   11.1333\n",
      "870    0  26.0       3      0      0    7.8958\n",
      "871    0  47.0       1      1      1   52.5542\n",
      "872    0  33.0       1      0      0    5.0000\n",
      "873    0  47.0       3      0      0    9.0000\n",
      "874    0  28.0       2      1      0   24.0000\n",
      "875    0  15.0       3      0      0    7.2250\n",
      "876    0  20.0       3      0      0    9.8458\n",
      "877    0  19.0       3      0      0    7.8958\n",
      "878    0   0.0       3      0      0    7.8958\n",
      "879    0  56.0       1      0      1   83.1583\n",
      "880    0  25.0       2      0      1   26.0000\n",
      "881    0  33.0       3      0      0    7.8958\n",
      "882    0  22.0       3      0      0   10.5167\n",
      "883    0  28.0       2      0      0   10.5000\n",
      "884    0  25.0       3      0      0    7.0500\n",
      "885    0  39.0       3      0      5   29.1250\n",
      "886    0  27.0       2      0      0   13.0000\n",
      "887    0  19.0       1      0      0   30.0000\n",
      "888    0   0.0       3      1      2   23.4500\n",
      "889    0  26.0       1      0      0   30.0000\n",
      "890    0  32.0       3      0      0    7.7500\n",
      "\n",
      "[891 rows x 6 columns]\n",
      "     Survived\n",
      "0           0\n",
      "1           1\n",
      "2           1\n",
      "3           1\n",
      "4           0\n",
      "5           0\n",
      "6           0\n",
      "7           0\n",
      "8           1\n",
      "9           1\n",
      "10          1\n",
      "11          1\n",
      "12          0\n",
      "13          0\n",
      "14          0\n",
      "15          1\n",
      "16          0\n",
      "17          1\n",
      "18          0\n",
      "19          1\n",
      "20          0\n",
      "21          1\n",
      "22          1\n",
      "23          1\n",
      "24          0\n",
      "25          1\n",
      "26          0\n",
      "27          0\n",
      "28          1\n",
      "29          0\n",
      "..        ...\n",
      "861         0\n",
      "862         1\n",
      "863         0\n",
      "864         0\n",
      "865         1\n",
      "866         1\n",
      "867         0\n",
      "868         0\n",
      "869         1\n",
      "870         0\n",
      "871         1\n",
      "872         0\n",
      "873         0\n",
      "874         1\n",
      "875         1\n",
      "876         0\n",
      "877         0\n",
      "878         0\n",
      "879         1\n",
      "880         1\n",
      "881         0\n",
      "882         0\n",
      "883         0\n",
      "884         0\n",
      "885         0\n",
      "886         0\n",
      "887         1\n",
      "888         0\n",
      "889         1\n",
      "890         0\n",
      "\n",
      "[891 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print('------------ Before Preprocessing ------------')\n",
    "# print the data before preprocessing\n",
    "dataset_X = data\n",
    "# Type is DataFrame\n",
    "print(type(dataset_X))\n",
    "\n",
    "# print the first 2 line of data\n",
    "print(dataset_X.iloc[0:2,:])\n",
    "\n",
    "print('\\n')\n",
    "print('------------ Start Preprocessing ------------')\n",
    "# fill in nan values with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# convert ['male', 'female'] values to [1, 0]\n",
    "data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "\n",
    "# add 'Deceased' as another class\n",
    "#data['Deceased'] = data['Survived'].apply(lambda s: 1 - s)\n",
    "\n",
    "# select features and labels for training\n",
    "dataset_X = data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare']]\n",
    "#dataset_Y = data[['Deceased', 'Survived']]\n",
    "dataset_Y = data[['Survived']]\n",
    "print(dataset_X)\n",
    "print(dataset_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Divide dataset to (training set) and (test set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevent from overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaohaonan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "/Users/zhaohaonan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split training data and test data (30% is test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset_X.as_matrix(), \n",
    "    dataset_Y.as_matrix(), \n",
    "    test_size = 0.2, \n",
    "    random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaohaonan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/zhaohaonan/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7374301675977654\n"
     ]
    }
   ],
   "source": [
    "print(LR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdata preprocessing\n",
    "testdata = pd.read_csv('data_set/test.csv')\n",
    "dataset_t = testdata\n",
    "testdata = testdata.fillna(0)\n",
    "# convert ['male', 'female'] values to [1, 0]\n",
    "testdata['Sex'] = testdata['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "# select features and labels for training\n",
    "dataset_t = testdata[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare']]\n",
    "\n",
    "pid = testdata[['PassengerId']]\n",
    "\n",
    "# list -> dataframe\n",
    "pre = LR.predict(dataset_t)\n",
    "pred = pd.DataFrame(pre, columns=['Survived'])\n",
    "result = pd.concat([pid, pred], axis=1)\n",
    "\n",
    "result.to_csv('titanic.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
